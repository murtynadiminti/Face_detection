<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Room Entry Alert</title>
  <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  <style>
    body { display:flex; flex-direction:column; align-items:center; font-family:Arial; background:#f9f9f9; }
    video, canvas { position:absolute; top:50%; left:50%; transform:translate(-50%,-50%); border:3px solid #333; border-radius:10px; }
    #status { margin-top:20px; font-size:18px; font-weight:bold; color:darkred; }
  </style>
</head>
<body>
  <h2>üö® Unknown Person Alert</h2>
  <video id="video" width="640" height="480" autoplay muted></video>
  <canvas id="overlay" width="640" height="480"></canvas>
  <p id="status">Loading models...</p>
  <audio id="alarm" src="https://actions.google.com/sounds/v1/alarms/alarm_clock.ogg"></audio>

  <script>
    const video = document.getElementById('video');
    const overlay = document.getElementById('overlay');
    const ctx = overlay.getContext('2d');
    const statusText = document.getElementById('status');
    const alarm = document.getElementById('alarm');

    let faceMatcher;

    async function startVideo() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
      video.srcObject = stream;
    }

    async function initSystem() {
      // Load models
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models'),
        faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models'),
        faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models')
      ]);

      startVideo();

      // Load registered face from storage
      const stored = localStorage.getItem("registeredFace");
      if (!stored) {
        statusText.textContent = "‚ö†Ô∏è No face registered! Open register.html first.";
        return;
      }

      const descriptor = new Float32Array(JSON.parse(stored));
      const labeledDescriptor = new faceapi.LabeledFaceDescriptors("Owner", [descriptor]);
      faceMatcher = new faceapi.FaceMatcher(labeledDescriptor, 0.6);

      statusText.textContent = "‚úÖ System Ready - Monitoring...";
    }

    video.addEventListener('play', () => {
      setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks().withFaceDescriptors();

        ctx.clearRect(0,0,overlay.width,overlay.height);
        const resized = faceapi.resizeResults(detections, { width: video.width, height: video.height });

        let unknownDetected = false;

        resized.forEach(detection => {
          const box = detection.detection.box;
          const bestMatch = faceMatcher.findBestMatch(detection.descriptor);
          ctx.strokeStyle = bestMatch.label === "unknown" ? "red" : "green";
          ctx.lineWidth = 3;
          ctx.strokeRect(box.x, box.y, box.width, box.height);
          ctx.fillStyle = ctx.strokeStyle;
          ctx.font = "16px Arial";
          ctx.fillText(bestMatch.toString(), box.x, box.y - 10);

          if (bestMatch.label === "unknown") unknownDetected = true;
        });

        if (unknownDetected) {
          statusText.textContent = "‚ö†Ô∏è Unknown Person Detected!";
          alarm.play();
        } else {
          statusText.textContent = "‚úÖ No Unknown Detected.";
          alarm.pause();
          alarm.currentTime = 0;
        }
      }, 1000);
    });

    initSystem();
  </script>
</body>
</html>
